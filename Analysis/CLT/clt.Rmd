---
title: "CLT"
author: "Martín Ramírez Espinosa & Sergio Alejandro González Osorio"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

suppressPackageStartupMessages({
  library(dplyr)
  library(ggplot2)
})
```

## Experimento

Se toma una urna con 12 valores distintos, se extraen 9 bolas con reemplazo y se calcula la media de cada muestra. Este procedimiento se repite 50 veces para estudiar cómo se comporta la distribución de las medias muestrales.

## Preparación de los datos

```{r load-data}
dataset_path <- if (file.exists("dataset.csv")) {
  "dataset.csv"
} else if (file.exists(file.path("Analysis", "CLT", "dataset.csv"))) {
  file.path("Analysis", "CLT", "dataset.csv")
} else {
  stop("No se encontró el archivo dataset.csv.")
}

clt_data <- read.csv(dataset_path)
sample_means <- clt_data$mean

knitr::kable(head(clt_data[, c("sample", "mean")]),
             col.names = c("Muestra", "Media"),
             caption = "Primeras medias muestrales registradas.")
```

## Gran media de las medias

La **gran media** corresponde al promedio de las 50 medias muestrales. Según el Teorema del Límite Central (TLC), esta cantidad es un estimador insesgado de la media poblacional y su dispersión se reduce conforme aumenta el número de réplicas. En este caso obtenemos:

```{r grand-mean, results='asis'}
grand_mean <- mean(sample_means)
sd_means <- sd(sample_means)
se_grand_mean <- sd_means / sqrt(length(sample_means))

summary_tbl <- data.frame(
  Estadístico = c("Número de réplicas", "Gran media", "Desviación de las medias", "Error estándar de la gran media"),
  Valor = c(length(sample_means),
            round(grand_mean, 2),
            round(sd_means, 2),
            round(se_grand_mean, 2))
)

knitr::kable(summary_tbl,
             align = "lc",
             caption = "Resumen numérico de las medias muestrales.")
```

La gran media obtenida es `r round(grand_mean, 2)`, lo que resume la tendencia central de las 50 medias. El error estándar (`r round(se_grand_mean, 2)`) cuantifica la incertidumbre asociada a este estimador.

## Evidencia gráfica del TLC

Como las medias posibles solo toman valores discretos, es más apropiado representar sus probabilidades mediante un gráfico tipo tallo (similar a `np.stem`) y superponer la masa normal esperada y la función de densidad analítica del TLC. A continuación se calcula cada componente paso a paso para mantener la coherencia matemática:

```{r stem-plot, fig.cap="Probabilidades discretas de las medias muestrales frente a la aproximación normal"}
calc_interval_bounds <- function(values) {
  values <- sort(values)
  n <- length(values)
  if (n == 1) {
    return(data.frame(lower = -Inf, upper = Inf))
  }
  midpoints <- (values[-1] + values[-n]) / 2
  data.frame(
    lower = c(-Inf, midpoints),
    upper = c(midpoints, Inf)
  )
}

empirical_tbl <- clt_data |>
  dplyr::count(mean, name = "freq") |>
  dplyr::arrange(mean) |>
  dplyr::mutate(prob = freq / sum(freq))

bounds <- calc_interval_bounds(empirical_tbl$mean)
if (sd_means > 0) {
  theory_prob <- pnorm(bounds$upper, mean = grand_mean, sd = sd_means) -
                 pnorm(bounds$lower, mean = grand_mean, sd = sd_means)
} else {
  theory_prob <- as.numeric(empirical_tbl$mean == grand_mean)
}

empirical_tbl <- empirical_tbl |>
  dplyr::mutate(
    lower = bounds$lower,
    upper = bounds$upper,
    theory_prob = theory_prob
  )

spacing <- if (nrow(empirical_tbl) > 1) min(diff(empirical_tbl$mean)) else max(sd_means, 1)
if (!is.finite(spacing) || spacing == 0) spacing <- 1
offset <- spacing * 0.25

empirical_tbl <- empirical_tbl |>
  dplyr::mutate(theory_x = mean + offset)

if (sd_means > 0) {
  padding <- spacing
  density_df <- data.frame(
    x = seq(min(empirical_tbl$mean) - padding,
            max(empirical_tbl$mean) + padding,
            length.out = 500)
  )
  density_df$density <- dnorm(density_df$x, mean = grand_mean, sd = sd_means)
  max_density <- max(density_df$density)
  scale_factor <- if (max_density > 0) {
    max(empirical_tbl$prob) / max_density * 0.9
  } else {
    1
  }
  density_df$scaled_density <- density_df$density * scale_factor
} else {
  density_df <- data.frame(
    x = empirical_tbl$mean,
    scaled_density = NA_real_
  )
  scale_factor <- 1
}

ggplot(empirical_tbl, aes(x = mean)) +
  geom_segment(aes(xend = mean, y = 0, yend = prob),
               linewidth = 1.2,
               color = "#0D47A1") +
  geom_point(aes(y = prob),
             color = "#0D47A1",
             size = 2.5) +
  geom_segment(aes(x = theory_x, xend = theory_x, y = 0, yend = theory_prob),
               color = "#8E24AA",
               linewidth = 1,
               linetype = "dashed") +
  geom_point(aes(x = theory_x, y = theory_prob),
             color = "#8E24AA",
             shape = 17,
             size = 2.2) +
  geom_line(data = density_df,
            aes(x = x, y = scaled_density),
            color = "#E53935",
            linewidth = 1) +
  scale_y_continuous(
    name = "Probabilidad discreta",
    sec.axis = sec_axis(
      trans = ~ . / scale_factor,
      name = "Densidad normal"
    )
  ) +
  labs(
    x = "Media de cada muestra",
    title = "Distribución discreta vs. aproximación normal",
    subtitle = "Azul: probabilidad empírica | Morado: masa normal integrada | Rojo: pdf normal"
  ) +
  annotate(
    "text",
    x = min(empirical_tbl$mean),
    y = max(empirical_tbl$prob) * 0.9,
    label = paste0("Gran media ≈ ", round(grand_mean, 2),
                   "  -  sd(medias) ≈ ", round(sd_means, 2)),
    hjust = 0,
    color = "#0D47A1",
    size = 3.1
  ) +
  theme_minimal(base_size = 11) +
  theme(
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank(),
    axis.title.y.right = element_text(color = "#E53935"),
    axis.text.y.right = element_text(color = "#E53935")
  )
```

Los tallos azules recogen la probabilidad empírica exacta de cada media observada, los tallos morados representan la masa que la normal asigna al intervalo de valores contiguos, y la línea roja es la función analítica
\[
f_{\bar{X}}(x)=\frac{1}{\sigma_{\bar{X}}\sqrt{2\pi}}
\exp\!\left(-\frac{(x-\mu_{\bar{X}})^2}{2\sigma_{\bar{X}}^2}\right),
\]
evaluada con `r round(grand_mean, 2)` y `r round(sd_means, 2)` como estimadores de \(\mu_{\bar{X}}\) y \(\sigma_{\bar{X}}\). La cercanía entre ambas representaciones evidencia cómo las medias (aun siendo discretas) siguen la forma normal predicha por el Teorema del Límite Central.
